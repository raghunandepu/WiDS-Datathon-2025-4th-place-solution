{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc0431-30ba-43f3-bce2-13eff053193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "INPUT_DATA_PATH = \"H:/widsdatathon2025\" # Replace your input data path here\n",
    "# -------------------------\n",
    "# Load data\n",
    "# -------------------------\n",
    "cat_fea = [\n",
    "    'participant_id', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu',\n",
    "    'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ'\n",
    "]\n",
    "\n",
    "def get_feats(mode='train'):\n",
    "    if mode == 'TRAIN_NEW':\n",
    "        feats = pd.read_excel(f\"{INPUT_DATA_PATH}/{mode}/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "    else:\n",
    "        feats = pd.read_excel(f\"{INPUT_DATA_PATH}/{mode}/{mode}_QUANTITATIVE_METADATA.xlsx\")\n",
    "\n",
    "    if mode == 'TRAIN_NEW':\n",
    "        cate = pd.read_excel(f\"{INPUT_DATA_PATH}/{mode}/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "    else:\n",
    "        cate = pd.read_excel(f\"{INPUT_DATA_PATH}/{mode}/{mode}_CATEGORICAL.xlsx\")\n",
    "\n",
    "    cate = cate.loc[:, cat_fea]\n",
    "    feats = feats.merge(cate, on='participant_id', how='left')\n",
    "\n",
    "    if mode == 'TEST':\n",
    "        func = pd.read_csv(f\"{INPUT_DATA_PATH}/{mode}/{mode}_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "    else:\n",
    "        func = pd.read_csv(f\"{INPUT_DATA_PATH}/{mode}/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "\n",
    "    global func_fea\n",
    "    func_fea = func.columns.to_list()\n",
    "    func_fea.remove('participant_id')\n",
    "    feats = feats.merge(func, on='participant_id', how='left')\n",
    "\n",
    "    if mode == 'TRAIN_NEW':\n",
    "        solution = pd.read_excel(\"{INPUT_DATA_PATH}/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
    "        feats = feats.merge(solution, on='participant_id', how='left')\n",
    "\n",
    "    return feats\n",
    "\n",
    "train = get_feats(mode='TRAIN_NEW')\n",
    "test = get_feats(mode='TEST')\n",
    "\n",
    "# -------------------------\n",
    "# One-hot encode categoricals\n",
    "# -------------------------\n",
    "cat_fea.remove('participant_id')\n",
    "train = pd.get_dummies(train, columns=cat_fea)\n",
    "test = pd.get_dummies(test, columns=cat_fea)\n",
    "train, test = train.align(test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# -------------------------\n",
    "# Prepare features\n",
    "# -------------------------\n",
    "exclude_cols = func_fea + ['participant_id', 'ADHD_Outcome', 'Sex_F']\n",
    "metadata_features = [col for col in train.columns if col not in exclude_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718eae42-7262-4801-bb47-cea1d3c1ad40",
   "metadata": {},
   "source": [
    "## train_ensemble_with_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718922e8-fdba-40cc-aa1a-1ac65c7fe1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c03f271-3222-403c-b0a9-2a7e4871a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Threshold tuner\n",
    "def find_best_threshold(y_true, y_probs):\n",
    "    thresholds = np.linspace(0.1, 0.9, 81)\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "    for t in thresholds:\n",
    "        preds = (y_probs >= t).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = t\n",
    "    return best_thresh\n",
    "\n",
    "# PCA selector\n",
    "def select_pca_components(X, explained_var_threshold=0.90):\n",
    "    pca = PCA(n_components=None, random_state=42)\n",
    "    pca.fit(X)\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(cumulative_variance >= explained_var_threshold) + 1\n",
    "    return n_components\n",
    "\n",
    "# Main ensemble CV trainer\n",
    "def train_ensemble_with_cv(train, test, target_col, func_fea, metadata_features):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    val_preds = np.zeros(train.shape[0])\n",
    "    test_preds_proba = np.zeros(test.shape[0])\n",
    "    thresholds = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train[target_col])):\n",
    "        print(f\"\\n PCA Fold {fold}\")\n",
    "        X_train_func = train.loc[train_idx, func_fea]\n",
    "        X_val_func = train.loc[val_idx, func_fea]\n",
    "        X_test_func = test[func_fea]\n",
    "\n",
    "        n_components = select_pca_components(X_train_func, explained_var_threshold=0.90)\n",
    "        print(\"Number of components selected:\", n_components)\n",
    "\n",
    "        pca = PCA(n_components=n_components, random_state=42)\n",
    "        X_train_pca = pca.fit_transform(X_train_func)\n",
    "        X_val_pca = pca.transform(X_val_func)\n",
    "        X_test_pca = pca.transform(X_test_func)\n",
    "\n",
    "        X_train_meta = train.loc[train_idx, metadata_features].values\n",
    "        X_val_meta = train.loc[val_idx, metadata_features].values\n",
    "        X_test_meta = test[metadata_features].values\n",
    "\n",
    "        # Impute metadata to handle NaNs (required for RidgeClassifier)\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train_meta = imputer.fit_transform(X_train_meta)\n",
    "        X_val_meta = imputer.transform(X_val_meta)\n",
    "        X_test_meta = imputer.transform(X_test_meta)\n",
    "        \n",
    "        # Combine metadata + PCA features\n",
    "        X_train_final = np.hstack([X_train_meta, X_train_pca])\n",
    "        X_val_final = np.hstack([X_val_meta, X_val_pca])\n",
    "        X_test_final = np.hstack([X_test_meta, X_test_pca])\n",
    "\n",
    "        y_train = train.loc[train_idx, target_col].values\n",
    "        y_val = train.loc[val_idx, target_col].values\n",
    "\n",
    "        # === Models ===\n",
    "        \n",
    "\n",
    "        model = VotingClassifier(estimators=[\n",
    "            ('lgbm', LGBMClassifier(device='gpu', n_estimators=800, learning_rate=0.03, class_weight='balanced', random_state=42)),\n",
    "            ('xgb', XGBClassifier(device='cuda', predictor='gpu_predictor',tree_method='hist', use_label_encoder=False,\n",
    "                                  eval_metric='logloss', learning_rate=0.03, n_estimators=800, scale_pos_weight=1.5, random_state=42)),\n",
    "            ('cat', CatBoostClassifier(iterations=800, learning_rate=0.03, depth=6, task_type=\"GPU\", devices=\"0\",\n",
    "                                       class_weights=[1, 2], verbose=0, random_seed=42)),\n",
    "            ('logreg', LogisticRegression(class_weight='balanced', max_iter=1000, solver='liblinear'))],\n",
    "          voting='soft', n_jobs=-1)\n",
    "\n",
    "\n",
    "        model.fit(X_train_final, y_train)\n",
    "\n",
    "        # Predict proba and tune threshold\n",
    "        val_probs = model.predict_proba(X_val_final)[:, 1]\n",
    "        best_thresh = find_best_threshold(y_val, val_probs)\n",
    "        thresholds.append(best_thresh)\n",
    "        val_pred = (val_probs >= best_thresh).astype(int)\n",
    "        val_preds[val_idx] = val_pred\n",
    "\n",
    "        test_probs = model.predict_proba(X_test_final)[:, 1]\n",
    "        test_preds_proba += test_probs\n",
    "\n",
    "        f1_val = f1_score(y_val, val_pred)\n",
    "        print(f\"Fold {fold} - Val F1: {f1_val:.4f}\")\n",
    "\n",
    "    # Final threshold (mean of bbest thresholds)\n",
    "    final_threshold = np.mean(thresholds)\n",
    "    print(f\"\\n Final Threshold: {final_threshold:.4f}\")\n",
    "\n",
    "    test_preds_proba /= skf.n_splits\n",
    "    test_preds = (test_preds_proba >= final_threshold).astype(int)\n",
    "\n",
    "    # Final CV evaluation\n",
    "    y_true = train[target_col]\n",
    "    print(\"\\n Final CV Results\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, val_preds):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, val_preds):.4f}\")\n",
    "    print(classification_report(y_true, val_preds))\n",
    "\n",
    "    return test_preds, val_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4254782-06c3-436d-96f9-e3427bd81dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… PCA Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [22:14:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Val F1: 0.9101\n",
      "\n",
      "âœ… PCA Fold 1\n",
      "Fold 1 - Val F1: 0.8667\n",
      "\n",
      "âœ… PCA Fold 2\n",
      "Fold 2 - Val F1: 0.8659\n",
      "\n",
      "âœ… PCA Fold 3\n",
      "Fold 3 - Val F1: 0.8835\n",
      "\n",
      "âœ… PCA Fold 4\n",
      "Fold 4 - Val F1: 0.8412\n",
      "\n",
      "ðŸŽ¯ Final Threshold: 0.2700\n",
      "\n",
      "ðŸ“Š Final CV Results\n",
      "Accuracy: 0.8120\n",
      "F1 Score: 0.8735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.52      0.63       382\n",
      "           1       0.81      0.95      0.87       831\n",
      "\n",
      "    accuracy                           0.81      1213\n",
      "   macro avg       0.81      0.73      0.75      1213\n",
      "weighted avg       0.81      0.81      0.80      1213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adhd_preds, adhd_val = train_ensemble_with_cv(train, test, 'ADHD_Outcome', func_fea, metadata_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a05322-7773-47d1-a1a2-b1a0288da6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… PCA Fold 0\n",
      "Fold 0 - Val F1: 0.5968\n",
      "\n",
      "âœ… PCA Fold 1\n",
      "Fold 1 - Val F1: 0.6102\n",
      "\n",
      "âœ… PCA Fold 2\n",
      "Fold 2 - Val F1: 0.6848\n",
      "\n",
      "âœ… PCA Fold 3\n",
      "Fold 3 - Val F1: 0.6073\n",
      "\n",
      "âœ… PCA Fold 4\n",
      "Fold 4 - Val F1: 0.6667\n",
      "\n",
      "ðŸŽ¯ Final Threshold: 0.2560\n",
      "\n",
      "ðŸ“Š Final CV Results\n",
      "Accuracy: 0.6810\n",
      "F1 Score: 0.6297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       797\n",
      "           1       0.52      0.79      0.63       416\n",
      "\n",
      "    accuracy                           0.68      1213\n",
      "   macro avg       0.69      0.71      0.67      1213\n",
      "weighted avg       0.74      0.68      0.69      1213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sex_preds, sex_val = train_ensemble_with_cv(train, test, 'Sex_F', func_fea, metadata_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab9e701b-91be-45c9-91ab-2ca7ab872275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Saved: submission_20250503_224252.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"participant_id\": test[\"participant_id\"],\n",
    "    \"ADHD_Outcome\": adhd_preds,\n",
    "    \"Sex_F\": sex_preds\n",
    "})\n",
    "\n",
    "filename = f\"submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"\\nâœ… Saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1203ae-bb84-4f0c-8f65-7e868bc4901e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
